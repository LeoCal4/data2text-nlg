pretrained_model: "gpt2-medium"
checkpoint_epoch: 4
checkpoint_step: 1276
convert_slot_names: True
batch_size: 1
max_seq_length: 512
num_beams: 10
beam_search_early_stopping: True
do_sample: False
length_penalty: 2.0
#num_return_sequences: 1
semantic_reranking: True
