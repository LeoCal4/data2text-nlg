model_name: "gpt2"
pretrained: True
checkpoint_epoch: 13
checkpoint_step: 2104
convert_slot_names: True
batch_size: 20
max_seq_length: 128
num_beams: 10
beam_search_early_stopping: True
do_sample: False
#no_repeat_ngram_size: 3
#repetition_penalty: 2.5
#length_penalty: [1.5, 2.0, 3.0, 5.0, 10.0]
length_penalty: 1.0
#num_return_sequences: 1
semantic_reranking: True
use_token_type_ids: True
