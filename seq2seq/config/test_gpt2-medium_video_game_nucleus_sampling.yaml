pretrained_model: "gpt2-medium"
checkpoint_epoch: 4
checkpoint_step: 1276
convert_slot_names: True
batch_size: 1
max_seq_length: 512
do_sample: True
top_p: 0.3
top_k: 0
#length_penalty: 1.0
num_return_sequences: 10
semantic_reranking: True
