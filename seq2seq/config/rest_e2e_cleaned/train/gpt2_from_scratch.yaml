model_name: "gpt2"
pretrained: False
tokenizer_name: "gpt2-rest_e2e_cleaned"
lowercase: False
convert_slot_names: False
num_epochs: 15
batch_size: 16
eval_batch_size: 64
max_seq_length: 128
num_warmup_steps: 0
lr: 2.0e-5
max_grad_norm: 1.0
eval_times_per_epoch: 1
fp16: True
use_token_type_ids: True
